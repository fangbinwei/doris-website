"use strict";(self.webpackChunkselectdb_portal=self.webpackChunkselectdb_portal||[]).push([[76253],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>m});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function l(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?l(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):l(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},l=Object.keys(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(n=0;n<l.length;n++)a=l[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},h="mdxType",d={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},p=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),h=c(a),p=r,m=h["".concat(s,".").concat(p)]||h[p]||d[p]||l;return a?n.createElement(m,i(i({ref:t},u),{},{components:a})):n.createElement(m,i({ref:t},u))}));function m(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=a.length,i=new Array(l);i[0]=p;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[h]="string"==typeof e?e:r,i[1]=o;for(var c=2;c<l;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}p.displayName="MDXCreateElement"},37720:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>h,frontMatter:()=>l,metadata:()=>o,toc:()=>c});var n=a(87462),r=(a(67294),a(3905));const l={title:"QUERY CACHE",language:"en"},i=void 0,o={unversionedId:"administrator-guide/query_cache",id:"version-0.15/administrator-guide/query_cache",title:"QUERY CACHE",description:"\x3c!--",source:"@site/versioned_docs/version-0.15/administrator-guide/query_cache.md",sourceDirName:"administrator-guide",slug:"/administrator-guide/query_cache",permalink:"/docs/0.15/administrator-guide/query_cache",draft:!1,tags:[],version:"0.15",frontMatter:{title:"QUERY CACHE",language:"en"}},s={},c=[{value:"1 Demond",id:"1-demond",level:2},{value:"2 Solutions",id:"2-solutions",level:2},{value:"3 Explanation of terms",id:"3-explanation-of-terms",level:2},{value:"4 Design",id:"4-design",level:2},{value:"1 <code>result cache</code>",id:"1-result-cache",level:3},{value:"<code>result_cache_ttl</code>",id:"result_cache_ttl",level:4},{value:"<code> result_cache_version</code>",id:"-result_cache_version",level:4},{value:"2 <code>partition_cache</code>",id:"2-partition_cache",level:3},{value:"5 usage",id:"5-usage",level:2},{value:"6 parameter",id:"6-parameter",level:2},{value:"fe",id:"fe",level:3},{value:"be",id:"be",level:3},{value:"7 how to use",id:"7-how-to-use",level:2}],u={toc:c};function h(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"query-cache"},"QUERY CACHE"),(0,r.kt)("h2",{id:"1-demond"},"1 Demond"),(0,r.kt)("p",null,"Although the corresponding cache is also made in the database storage layer, the cache in the database storage layer is generally aimed at the query content, and the granularity is too small. Generally, only when the data in the table is not changed can the corresponding cache of the database play a role. However, this can not reduce the huge IO pressure brought by the addition, deletion and query of the database by the business system. Therefore, the database cache technology was born here to realize the cache of hot data, improve the response speed of the application, and greatly relieve the pressure of the back-end database"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"High concurrency scenarios\nDoris have a well support for high concurrency while single sever is unable to load too high QPS.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Complex Graph Dashboard\nIt is not uncommon to see that,  data of the complex Dashboard and the large screen applications come from many table together which have tens of queries in a single page.Even though every single query cost only few milliseconds, the total queries would cost seconds.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Trend Analysis\nIn some scenarios, the queries are in a given date range , the index is shown by date.For example, we want to query the trend of the number of user in the last 7 days.This type of queries has a large amount of data and a wide range of fields, and the queries often takes tens of seconds.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"User repeated query\nIf the product does not have an anti-re-flash mechanism, the user accidentally  refreshes the page repeatedly due many reasons, which resulting in submitting a large number of repeated SQL"))),(0,r.kt)("p",null,"In the above four scenarios, we have solutions at the application layer. We put the result of queries in the Redis and  update the cache periodically or the user update the cache manually.However, this solution has the following problems:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Inconsistence of data , we are unable to sense the update of data, causing users to often see old data")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Low hit rate, we usually cache the whole result of query.If the data is writed real-time, we would often failed in cache, resulting in low hit rate and overload for the system.")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("p",{parentName:"li"},"Extra Cost we introduce external cache components, which will bring system complexity and increase additional costs."))),(0,r.kt)("h2",{id:"2-solutions"},"2 Solutions"),(0,r.kt)("p",null,"At present, we design two modules: result cache and partition cache"),(0,r.kt)("h2",{id:"3-explanation-of-terms"},"3 Explanation of terms"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"result cache")),(0,r.kt)("p",null,"SQL directly caches the result collection of queries for users"),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},"partition cache")),(0,r.kt)("p",null,"In the partition granularity, cache the results of each partition query"),(0,r.kt)("h2",{id:"4-design"},"4 Design"),(0,r.kt)("h3",{id:"1-result-cache"},"1 ",(0,r.kt)("inlineCode",{parentName:"h3"},"result cache")),(0,r.kt)("p",null,"result",(0,r.kt)("em",{parentName:"p"},"cache is divided into two types. The first type is result")," cache",(0,r.kt)("em",{parentName:"p"}," The second type of TTL is result")," cache_ version"),(0,r.kt)("h4",{id:"result_cache_ttl"},(0,r.kt)("inlineCode",{parentName:"h4"},"result_cache_ttl")),(0,r.kt)("p",null,"result",(0,r.kt)("em",{parentName:"p"}," cache")," ttl  variable is set in the user session. The user can customize whether to turn it on or not. The TTL time is used to determine whether the user's SQL uses cache. The correctness of the data is not guaranteed when the data is changed`"),(0,r.kt)("p",null,"The cache is stored and retrieved according to the user connected and the query SQL. If it exceeds the cache expiration time, the cache will not be hit and the cache will be cleaned"),(0,r.kt)("h4",{id:"-result_cache_version"},(0,r.kt)("inlineCode",{parentName:"h4"}," result_cache_version")),(0,r.kt)("p",null,"result",(0,r.kt)("em",{parentName:"p"}," cache")," version stores and fetches the cache according to the signature of SQL, partition ID of the query table, latest version of partition. The combination of the three determines a cache dataset. If any one of them changes, such as SQL changes, query fields or conditions are not the same, or the version after data update changes, the cache will not be hit."),(0,r.kt)("p",null,"If multiple tables are joined, the latest partition ID and the latest version number are used. If one of the tables is updated, the partition ID or version number will be different, and the cache will not be hit."),(0,r.kt)("h3",{id:"2-partition_cache"},"2 ",(0,r.kt)("inlineCode",{parentName:"h3"},"partition_cache")),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"SQL can be split in parallel, Q = Q1 \u222a Q2 ... \u222a Qn, R= R1 \u222a R2 ... \u222a Rn, Q is the query statement and R is the result set"),(0,r.kt)("li",{parentName:"ol"},"Split into read-only partition and updatable partition, read-only partition cache, update partition not cache")),(0,r.kt)("h2",{id:"5-usage"},"5 usage"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"cache type"),(0,r.kt)("th",{parentName:"tr",align:null},"usage"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"result_cache_ttl"),(0,r.kt)("td",{parentName:"tr",align:null},"Mainly solve the scenario of high QPS and repeated query by users")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"result_cache_version"),(0,r.kt)("td",{parentName:"tr",align:null},"It mainly solves the scenario that the whole table has not changed for a long time")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"partition_cache"),(0,r.kt)("td",{parentName:"tr",align:null},"It mainly solves the scenario that the historical partition does not change")))),(0,r.kt)("h2",{id:"6-parameter"},"6 parameter"),(0,r.kt)("h3",{id:"fe"},"fe"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_per_query_max_row_count"))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Cache the maximum number of rows per query"),(0,r.kt)("li",{parentName:"ul"},"The default value is 3000")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_per_query_max_size_In_bytes"))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The size of each query in bytes"),(0,r.kt)("li",{parentName:"ul"},"The default value is 1MB")),(0,r.kt)("ol",{start:3},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"result_cache_ttl_In_milliseconds"))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Cache duration of result cache"),(0,r.kt)("li",{parentName:"ul"},"The default value is 3S")),(0,r.kt)("h3",{id:"be"},"be"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_max_partition_count"))),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Be maximum number of partitions cache",(0,r.kt)("em",{parentName:"li"}," max")," partition",(0,r.kt)("em",{parentName:"li"}," Count refers to the maximum number of partitions corresponding to each SQL. If the partition is based on date, the data can be cached for more than 2 years. If you want to keep the cache for a longer time, please set this parameter larger and modify the cache")," result",(0,r.kt)("em",{parentName:"li"}," max")," row_ Count parameter."),(0,r.kt)("li",{parentName:"ul"},"Default value : 1024")),(0,r.kt)("ol",{start:2},(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("inlineCode",{parentName:"li"},"cache_max_size_in_mb")," ",(0,r.kt)("inlineCode",{parentName:"li"},"cache_elasticity_size_in_mb")," ")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"The cache memory setting in backend has two parameters: cache",(0,r.kt)("em",{parentName:"li"},"max_size_In_mb(256) and cache_elasticity_size_In_mb(128), memory exceeds cache")," max_ size_In_mb+cache_elasticity_size_In_mb will clean up and control the memory to cache_max_size_In_mb. These two parameters can be set according to the number of be nodes, the memory size of nodes, and cache hit rate.")),(0,r.kt)("h2",{id:"7-how-to-use"},"7 how to use"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"use enable_result_cache_ttl")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"set `global`  enable_result_cache_ttl =true\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"use enable_result_cache_version")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"set `global` enable_result_cache_version = true\n")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"use enable_partition_cache")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"set `global` enable_partition_cache = true\n")))}h.isMDXComponent=!0}}]);